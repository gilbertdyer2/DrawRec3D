{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c587bea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, Input\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d502d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras import regularizers\n",
    "EMBED_DIM = 128  # final embedding size\n",
    "\n",
    "class L2Normalization(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(L2Normalization, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.math.l2_normalize(inputs, axis=1)\n",
    "\n",
    "    # REQUIRED for ONNX/Saving:\n",
    "    def get_config(self):\n",
    "        config = super(L2Normalization, self).get_config()\n",
    "        return config\n",
    "\n",
    "def build_encoder():\n",
    "    # Input: 128x128 distance matrix\n",
    "    mat_in = Input(shape=(128, 128, 2), name=\"dist_matrix\")\n",
    "    \n",
    "    # Block 1\n",
    "    x = layers.Conv2D(32, (5,5), padding=\"same\", kernel_regularizer=regularizers.l2(1e-4))(mat_in)\n",
    "    x = layers.BatchNormalization()(x) # Added BN\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.MaxPool2D((2,2))(x)\n",
    "    \n",
    "    # Block 2\n",
    "    x = layers.Conv2D(64, (3,3), padding=\"same\", kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "    x = layers.BatchNormalization()(x) # Added BN\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.MaxPool2D((2,2))(x)\n",
    "    \n",
    "    # Block 3\n",
    "    x = layers.Conv2D(128, (3,3), padding=\"same\", kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "    x = layers.BatchNormalization()(x) # Added BN\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    \n",
    "    # Block 4 (Optional: Go deeper since we have more data now)\n",
    "    x = layers.MaxPool2D((2,2))(x)\n",
    "    x = layers.Conv2D(256, (3,3), padding=\"same\", kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    \n",
    "    # Dual Pooling: Capture both peak features and average intensity\n",
    "    gmax = layers.GlobalMaxPooling2D()(x)\n",
    "    gavg = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Concatenate()([gmax, gavg]) # Feature vector size doubles\n",
    "    \n",
    "    # Dense Head\n",
    "    x = layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.4)(x) # Increased dropout slightly for larger model\n",
    "    \n",
    "    # Embedding\n",
    "    # Increased dim to 128 to capture more nuance in 16 classes\n",
    "    emb = layers.Dense(128, activation=None, name=\"embedding\")(x)\n",
    "    emb = L2Normalization()(emb)\n",
    "\n",
    "    return models.Model(mat_in, emb, name=\"drawing_encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607db10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_siamese(encoder):\n",
    "    matA = Input(shape=(128, 128, 2), name=\"matrix_A\")\n",
    "    matB = Input(shape=(128, 128, 2), name=\"matrix_B\")\n",
    "\n",
    "    embA = encoder(matA)\n",
    "    embB = encoder(matB)\n",
    "\n",
    "    dist = layers.Lambda(\n",
    "        lambda x: tf.sqrt(tf.reduce_sum(tf.square(x[0] - x[1]), axis=1, keepdims=True) + 1e-7)\n",
    "    )([embA, embB])\n",
    "\n",
    "    return models.Model([matA, matB], dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bc1a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(y_true, y_pred, margin=1.0):\n",
    "    \"\"\"\n",
    "    y_true: 1 if same class, 0 if different\n",
    "    y_pred: distance between embeddings\n",
    "    \"\"\"\n",
    "    squared = tf.square(y_pred)\n",
    "    margin_squared = tf.square(tf.maximum(margin - y_pred, 0))\n",
    "    return tf.reduce_mean(y_true * squared + (1 - y_true) * margin_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dde0bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def make_pairs(matrices, labels, batch_size=8):\n",
    "    \"\"\"\n",
    "    Yield batches of distance matrix pairs and targets.\n",
    "    \"\"\"\n",
    "    num_samples = len(matrices)\n",
    "    \n",
    "    # Pre-group indices by class for fast positive sampling\n",
    "    class_to_idxs = {}\n",
    "    for idx, c in enumerate(labels):\n",
    "        class_to_idxs.setdefault(c, []).append(idx)\n",
    "\n",
    "    while True:\n",
    "        matA_batch, matB_batch, y_batch = [], [], []\n",
    "\n",
    "        for _ in range(batch_size):\n",
    "            anchor_idx = random.randrange(num_samples)\n",
    "            anchor_label = labels[anchor_idx]\n",
    "\n",
    "            # Positive pair 50%\n",
    "            if random.random() < 0.5:\n",
    "                pos_idx = random.choice(class_to_idxs[anchor_label])\n",
    "                while pos_idx == anchor_idx:\n",
    "                    pos_idx = random.choice(class_to_idxs[anchor_label])\n",
    "                matA_batch.append(matrices[anchor_idx])\n",
    "                matB_batch.append(matrices[pos_idx])\n",
    "                y_batch.append(1.0)\n",
    "            # Negative pair 50%\n",
    "            else:\n",
    "                neg_label = random.choice([l for l in class_to_idxs.keys() if l != anchor_label])\n",
    "                neg_idx = random.choice(class_to_idxs[neg_label])\n",
    "                matA_batch.append(matrices[anchor_idx])\n",
    "                matB_batch.append(matrices[neg_idx])\n",
    "                y_batch.append(0.0)\n",
    "\n",
    "        yield (\n",
    "            (np.array(matA_batch), np.array(matB_batch)),\n",
    "            np.array(y_batch).reshape(-1, 1)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d42b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = build_encoder()\n",
    "siamese = build_siamese(encoder)\n",
    "\n",
    "siamese.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "    loss=contrastive_loss\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b214a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data_train = np.load('drawing_dataset.npz', allow_pickle=True)  # must allow pickle for object arrays\n",
    "X_train = data_train['X']  # drawings\n",
    "y_train = data_train['y']  # labels\n",
    "\n",
    "data_val = np.load('validation_dataset.npz', allow_pickle=True)\n",
    "X_val = data_val['X']\n",
    "y_val = data_val['y']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6277f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance_matrix(points):\n",
    "    \"\"\"\n",
    "    points: (num_points, 3)\n",
    "    returns: (num_points, num_points) distance matrix\n",
    "    \"\"\"\n",
    "    points = np.asarray(points, dtype=np.float32)\n",
    "\n",
    "    diff = points[:, None, :] - points[None, :, :]\n",
    "    dist = np.linalg.norm(diff, axis=-1)\n",
    "\n",
    "    scale = np.max(dist)\n",
    "    return dist / (scale + 1e-8)\n",
    "\n",
    "def process_matrices(X_raw):\n",
    "    \"\"\"\n",
    "    Converts raw drawing points into formatted distance matrices\n",
    "    \"\"\"\n",
    "    # Ensure input is a consistent array of arrays\n",
    "    X_processed = np.array([np.array(p, dtype=np.float32) for p in X_raw])\n",
    "    \n",
    "    # Compute distance matrices\n",
    "    matrices = np.array([compute_distance_matrix(p) for p in X_processed])\n",
    "    \n",
    "    # Add channel dimension for Conv2D (N, 128, 128, 1)\n",
    "    matrices = matrices[..., np.newaxis]\n",
    "    return matrices\n",
    "\n",
    "def compute_distance_matrix_heightchannel(points):\n",
    "    \"\"\"\n",
    "    points: (num_points, 3)\n",
    "    returns: (num_points, num_points, 2) -> [Distance, Y-Diff]\n",
    "    \"\"\"\n",
    "    points = np.asarray(points, dtype=np.float32)\n",
    "\n",
    "    # Channel 1: Euclidean Distance\n",
    "    diff = points[:, None, :] - points[None, :, :]\n",
    "    dist = np.linalg.norm(diff, axis=-1)\n",
    "    \n",
    "    # Global scale for normalization (applied to both channels to keep aspect ratio)\n",
    "    scale = np.max(dist) + 1e-8\n",
    "    dist_norm = dist / scale\n",
    "\n",
    "    # Channel 2: Y-Axis Difference\n",
    "    # Calculates (y1 - y2) for every point pair\n",
    "    y_diff = points[:, 1][:, None] - points[None, :, 1]\n",
    "    y_diff_norm = y_diff / scale\n",
    "\n",
    "    # Stack them: Result is (128, 128, 2)\n",
    "    return np.stack([dist_norm, y_diff_norm], axis=-1)\n",
    "\n",
    "def process_matrices_heightchannel(X_raw):\n",
    "    \"\"\"\n",
    "    Converts raw drawing points into formatted 2-channel matrices\n",
    "    \"\"\"\n",
    "    X_processed = np.array([np.array(p, dtype=np.float32) for p in X_raw])\n",
    "    \n",
    "    # Compute 2-channel matrices\n",
    "    # Returns (N, 128, 128, 2)\n",
    "    matrices = np.array([compute_distance_matrix_heightchannel(p) for p in X_processed])\n",
    "    \n",
    "    return matrices\n",
    "\n",
    "\n",
    "train_matrices = process_matrices_heightchannel(X_train)\n",
    "val_matrices = process_matrices_heightchannel(X_val)\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "# Parameters\n",
    "batch_size = 64\n",
    "steps_per_epoch = 200\n",
    "epochs = 100\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def train_generator_fn():\n",
    "    return make_pairs(train_matrices, y_train, batch_size)\n",
    "\n",
    "def val_generator_fn():\n",
    "    return make_pairs(val_matrices, y_val, batch_size)\n",
    "\n",
    "# Use TF dataset, mostly to avoid restructuring other code to use numpy types\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    train_generator_fn,\n",
    "    output_signature=(\n",
    "        (\n",
    "            tf.TensorSpec(shape=(None, 128, 128, 2), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(None, 128, 128, 2), dtype=tf.float32)\n",
    "        ),\n",
    "        tf.TensorSpec(shape=(None, 1), dtype=tf.float32)\n",
    "    )\n",
    ")\n",
    "val_dataset = tf.data.Dataset.from_generator(\n",
    "    val_generator_fn,\n",
    "    output_signature=(\n",
    "        (\n",
    "            tf.TensorSpec(shape=(None, 128, 128, 2), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(None, 128, 128, 2), dtype=tf.float32)\n",
    "        ),\n",
    "        tf.TensorSpec(shape=(None, 1), dtype=tf.float32)\n",
    "    )\n",
    ")\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=20, # epochs without improvement\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = siamese.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=val_dataset,\n",
    "    validation_steps=5,\n",
    "    epochs=epochs,\n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff0f0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.save(\"drawing_encoder_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DrawRec3D_TF210",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
